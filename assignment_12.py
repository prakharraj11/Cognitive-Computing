# -*- coding: utf-8 -*-
"""Assignment_12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1quh1DD2CVWCzsEW1vBWP9xFVE9ymccb4

Q1). Deploy a Cognitive Systems or Chatbot for healthcare applications.
Use the following conversation-

'Hi',

'Hello! I am HealthBot. How can I assist you today?',

'Hello',

'Hi! Do you have a health-related question?',

'I have a headache',

'You should rest, stay hydrated, and take a mild pain reliever if needed.',

'What should I do if I have a fever?',

'Drink plenty of fluids and rest. If the fever persists, please consult a
doctor.',

'I feel dizzy',

'Sit down, breathe deeply, and drink water. If it continues, seek medical help.
'
,
'What should I eat for a cold?',

'Warm fluids, soups, citrus fruits, and light meals help during a cold.',
'How to stay healthy?',

'Eat balanced meals, exercise regularly, stay hydrated, and get enough sleep.',
'What should I do in case of a cut?',

'Clean the wound with water, apply antiseptic, and cover it with a clean bandage.',

'How much water should I drink daily?',

'Generally, 2 to 3 liters per day is recommended, but it varies based on your
activity.',

'Thank you',

'You’re welcome! Take care.',

'Bye',

'Goodbye! Stay healthy.'
"""

!pip install transformers Datasets torch

from datasets import Dataset
import pandas as pd
import torch
from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments

from datasets import Dataset
import pandas as pd

data = [
    {"User": "Hi", "Bot": "Hello! How can I assist you today?"},
    {"User": "I have a headache", "Bot": "You should rest, stay hydrated, and take a mild pain reliever if needed."},
    {"User": "What should I do if I have a fever?", "Bot": "Drink plenty of fluids and rest. If the fever persists, please consult a doctor."},
    {"User": "I feel dizzy", "Bot": "Sit down, breathe deeply, and drink water. If it continues, seek medical help."},
    {"User": "What should I eat for a cold?", "Bot": "Warm fluids, soups, citrus fruits, and light meals help during a cold."},
    {"User": "How to stay healthy?", "Bot": "Eat balanced meals, exercise regularly, stay hydrated, and get enough sleep."},
    {"User": "What should I do in case of a cut?", "Bot": "Clean the wound with water, apply antiseptic, and cover it with a clean bandage."},
    {"User": "How much water should I drink daily?", "Bot": "Generally, 2 to 3 liters per day is recommended, but it varies based on your activity."},
    {"User": "Thank you", "Bot": "You’re welcome! Take care."},
    {"User": "Bye", "Bot": "Goodbye! Stay healthy."}
]

df = pd.DataFrame(data)
dataset = Dataset.from_pandas(df)
print(dataset)

from transformers import GPT2Tokenizer

tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
tokenizer.pad_token = tokenizer.eos_token

def tokenize(data):
    text = [f"{user} {bot}" for user, bot in zip(data['User'], data['Bot'])]

    encodings = tokenizer(text, truncation=True, padding=True, add_special_tokens=True)

    return {
        'input_ids': encodings['input_ids'],
        'attention_mask': encodings['attention_mask'],
        'labels': encodings['input_ids']
    }

tokenized_dataset = dataset.map(tokenize, batched=True)

from transformers import GPT2LMHeadModel, Trainer, TrainingArguments
import os

os.environ['CUDA_LAUNCH_BLOCKING']="1"
os.environ['TORCH_USE_CUDA_DSA'] = "1"

model = GPT2LMHeadModel.from_pretrained('gpt2')

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=2,
    save_steps=10_000,
    save_total_limit=2,
    logging_dir='./logs',
    save_strategy="epoch",
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
    tokenizer=tokenizer
)
trainer.train()

from transformers import GPT2LMHeadModel, GPT2Tokenizer

model = GPT2LMHeadModel.from_pretrained('./results/checkpoint-10')
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
tokenizer.pad_token = tokenizer.eos_token

def generate_response(user_input):
    inputs = tokenizer(user_input, return_tensors="pt", padding=True)
    input_ids = inputs["input_ids"]
    attention_mask = inputs["attention_mask"]
    output = model.generate(
        input_ids,
        max_length=50,
        attention_mask = attention_mask,
        num_return_sequences=1,
        no_repeat_ngram_size=2,
        top_k=50,
        top_p=0.95,
        temperature=0.7,
        pad_token_id=tokenizer.eos_token_id,
        eos_token_id=tokenizer.eos_token_id,
    )

    response = tokenizer.decode(output[0], skip_special_tokens=True)
    return response

# Test the model with some user input
user_input = "I have a headache"
response = generate_response(user_input)
print("Bot Response:", response)