{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwDyUj7AwA7pqLxlG+jcUQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakharraj11/Cognitive-Computing/blob/main/Assignment_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports,technology, food, books, etc.).\n",
        "1. Convert text to lowercase and remove punctuation using re.\n",
        "2. Tokenize the text into words and sentences.\n",
        "3. Split using split() and word_tokenize() and compare how Python split and NLTK’s\n",
        "word_tokenize() differ.\n",
        "4. Remove stopwords (using NLTK's stopwords list).\n",
        "5. Display word frequency distribution (excluding stopwords)."
      ],
      "metadata": {
        "id": "THTs_nR4Yz5Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJfezge7YXmU"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"\"\"Space exploration represents humanity's boldest ambition to reach beyond our planet and discover the mysteries of the cosmos. The technological innovations developed for space missions have\n",
        "       consistently transformed our daily lives, from satellite communications to advanced materials. Scientists and engineers around the world collaborate on ambitious projects that push the boundaries\n",
        "       of what we thought possible decades ago. Looking up at the stars reminds us of our relatively small place in the universe, yet inspires us to dream bigger. The future of space exploration holds\n",
        "       promise for discovering new worlds, resources, and perhaps even answering the ultimate question of whether we are alone in the universe.\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "LfSF_JMkafp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_s = s.lower()\n",
        "clean_s = re.sub(r\"[^\\w\\s']\", '', s)\n",
        "print(clean_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4fReZ49aqnw",
        "outputId": "4e1327ee-b7af-4c67-a0a4-73fff14fcfeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Space exploration represents humanity's boldest ambition to reach beyond our planet and discover the mysteries of the cosmos The technological innovations developed for space missions have\n",
            "       consistently transformed our daily lives from satellite communications to advanced materials Scientists and engineers around the world collaborate on ambitious projects that push the boundaries\n",
            "       of what we thought possible decades ago Looking up at the stars reminds us of our relatively small place in the universe yet inspires us to dream bigger The future of space exploration holds\n",
            "       promise for discovering new worlds resources and perhaps even answering the ultimate question of whether we are alone in the universe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = clean_s.split()\n",
        "print(words)\n",
        "sentences = re.split(r'(?<=[.!?])\\s+', s)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK4SmbrhbAhH",
        "outputId": "3de09614-5553-486a-d8d7-418c8d508e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Space', 'exploration', 'represents', \"humanity's\", 'boldest', 'ambition', 'to', 'reach', 'beyond', 'our', 'planet', 'and', 'discover', 'the', 'mysteries', 'of', 'the', 'cosmos', 'The', 'technological', 'innovations', 'developed', 'for', 'space', 'missions', 'have', 'consistently', 'transformed', 'our', 'daily', 'lives', 'from', 'satellite', 'communications', 'to', 'advanced', 'materials', 'Scientists', 'and', 'engineers', 'around', 'the', 'world', 'collaborate', 'on', 'ambitious', 'projects', 'that', 'push', 'the', 'boundaries', 'of', 'what', 'we', 'thought', 'possible', 'decades', 'ago', 'Looking', 'up', 'at', 'the', 'stars', 'reminds', 'us', 'of', 'our', 'relatively', 'small', 'place', 'in', 'the', 'universe', 'yet', 'inspires', 'us', 'to', 'dream', 'bigger', 'The', 'future', 'of', 'space', 'exploration', 'holds', 'promise', 'for', 'discovering', 'new', 'worlds', 'resources', 'and', 'perhaps', 'even', 'answering', 'the', 'ultimate', 'question', 'of', 'whether', 'we', 'are', 'alone', 'in', 'the', 'universe']\n",
            "[\"Space exploration represents humanity's boldest ambition to reach beyond our planet and discover the mysteries of the cosmos.\", 'The technological innovations developed for space missions have\\n       consistently transformed our daily lives, from satellite communications to advanced materials.', 'Scientists and engineers around the world collaborate on ambitious projects that push the boundaries\\n       of what we thought possible decades ago.', 'Looking up at the stars reminds us of our relatively small place in the universe, yet inspires us to dream bigger.', 'The future of space exploration holds\\n       promise for discovering new worlds, resources, and perhaps even answering the ultimate question of whether we are alone in the universe.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "kubzIUXPc5V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpqaBQXVc6vZ",
        "outputId": "8274ed74-68fc-469c-a7de-d7350eb41498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize using nltk\n",
        "sentences = sent_tokenize(s)\n",
        "words = word_tokenize(clean_s)\n",
        "print(sentences)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRjZIprLc80d",
        "outputId": "b29b7a17-7aef-4914-8551-13000edc26f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Space exploration represents humanity's boldest ambition to reach beyond our planet and discover the mysteries of the cosmos.\", 'The technological innovations developed for space missions have\\n       consistently transformed our daily lives, from satellite communications to advanced materials.', 'Scientists and engineers around the world collaborate on ambitious projects that push the boundaries\\n       of what we thought possible decades ago.', 'Looking up at the stars reminds us of our relatively small place in the universe, yet inspires us to dream bigger.', 'The future of space exploration holds\\n       promise for discovering new worlds, resources, and perhaps even answering the ultimate question of whether we are alone in the universe.']\n",
            "['Space', 'exploration', 'represents', 'humanity', \"'s\", 'boldest', 'ambition', 'to', 'reach', 'beyond', 'our', 'planet', 'and', 'discover', 'the', 'mysteries', 'of', 'the', 'cosmos', 'The', 'technological', 'innovations', 'developed', 'for', 'space', 'missions', 'have', 'consistently', 'transformed', 'our', 'daily', 'lives', 'from', 'satellite', 'communications', 'to', 'advanced', 'materials', 'Scientists', 'and', 'engineers', 'around', 'the', 'world', 'collaborate', 'on', 'ambitious', 'projects', 'that', 'push', 'the', 'boundaries', 'of', 'what', 'we', 'thought', 'possible', 'decades', 'ago', 'Looking', 'up', 'at', 'the', 'stars', 'reminds', 'us', 'of', 'our', 'relatively', 'small', 'place', 'in', 'the', 'universe', 'yet', 'inspires', 'us', 'to', 'dream', 'bigger', 'The', 'future', 'of', 'space', 'exploration', 'holds', 'promise', 'for', 'discovering', 'new', 'worlds', 'resources', 'and', 'perhaps', 'even', 'answering', 'the', 'ultimate', 'question', 'of', 'whether', 'we', 'are', 'alone', 'in', 'the', 'universe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "print(stop_words)\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0w1RSnkdNcb",
        "outputId": "b273722c-db0d-4cfd-aed2-f5accec2c2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ll', 'there', 'both', 'ourselves', 'are', 'him', 'his', 'before', 'themselves', 'have', 'when', 'didn', \"it'll\", 'such', 'which', 'during', 'so', 'of', 'shouldn', \"mustn't\", 'herself', \"mightn't\", 'on', \"hasn't\", 'do', \"he'd\", 'below', \"we've\", 'ain', \"isn't\", \"we'd\", 'we', 'now', 'few', 'will', \"i've\", \"i'll\", 'more', 'your', 'again', 'nor', 'out', \"weren't\", \"you've\", 'weren', 'just', 'not', 'why', 'until', 'they', 'was', 'by', 'did', \"aren't\", 'wasn', 'wouldn', \"that'll\", 'above', 'itself', 'off', 'hers', 'y', 'himself', \"hadn't\", 'any', 'who', \"doesn't\", 'while', 'been', 'd', 'being', \"you'll\", \"she's\", 'where', 'be', \"i'd\", 'hadn', 'am', 'what', 'to', 'doing', 'up', 'from', \"wasn't\", 'ma', \"they're\", 'ours', 't', 'than', \"she'll\", 'this', 'these', 'her', 'mustn', 'same', 'it', 'no', 'other', 'how', 'here', 'at', \"haven't\", 'theirs', \"we're\", 'with', \"they'd\", 'too', 're', 'couldn', 'some', 'doesn', 'if', \"shouldn't\", 'then', 'isn', \"he's\", 'shan', 'most', \"wouldn't\", 'aren', 'all', 'won', \"it'd\", 'between', 'yours', 'a', 'hasn', 'over', 'i', 'yourself', 'after', 'into', \"needn't\", 'and', 'can', 'each', \"won't\", 'them', 'because', 'don', 'about', 'had', \"you'd\", 'that', \"didn't\", 'she', \"don't\", 'for', \"you're\", 'yourselves', 'is', 's', \"shan't\", 'mightn', \"i'm\", \"they've\", \"she'd\", 'needn', 'down', 'the', 've', 'were', 'haven', 'he', 'under', 'an', 'but', \"it's\", \"they'll\", 'my', 'through', 'o', 'only', \"couldn't\", \"should've\", 'further', \"he'll\", 'does', 'has', 'its', 'me', 'their', 'in', 'should', 'you', 'our', 'myself', 'once', \"we'll\", 'against', 'or', 'own', 'whom', 'm', 'having', 'as', 'very', 'those'}\n",
            "['Space', 'exploration', 'represents', 'humanity', \"'s\", 'boldest', 'ambition', 'reach', 'beyond', 'planet', 'discover', 'mysteries', 'cosmos', 'The', 'technological', 'innovations', 'developed', 'space', 'missions', 'consistently', 'transformed', 'daily', 'lives', 'satellite', 'communications', 'advanced', 'materials', 'Scientists', 'engineers', 'around', 'world', 'collaborate', 'ambitious', 'projects', 'push', 'boundaries', 'thought', 'possible', 'decades', 'ago', 'Looking', 'stars', 'reminds', 'us', 'relatively', 'small', 'place', 'universe', 'yet', 'inspires', 'us', 'dream', 'bigger', 'The', 'future', 'space', 'exploration', 'holds', 'promise', 'discovering', 'new', 'worlds', 'resources', 'perhaps', 'even', 'answering', 'ultimate', 'question', 'whether', 'alone', 'universe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word frequency count\n",
        "from collections import Counter\n",
        "word_freq = Counter(filtered_words)\n",
        "most_common = word_freq.most_common(10)\n",
        "print(word_freq)\n",
        "print(most_common)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jImNtPXdXMA",
        "outputId": "88382c06-1ca8-41e2-d7fe-426284ca0479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'exploration': 2, 'The': 2, 'space': 2, 'us': 2, 'universe': 2, 'Space': 1, 'represents': 1, 'humanity': 1, \"'s\": 1, 'boldest': 1, 'ambition': 1, 'reach': 1, 'beyond': 1, 'planet': 1, 'discover': 1, 'mysteries': 1, 'cosmos': 1, 'technological': 1, 'innovations': 1, 'developed': 1, 'missions': 1, 'consistently': 1, 'transformed': 1, 'daily': 1, 'lives': 1, 'satellite': 1, 'communications': 1, 'advanced': 1, 'materials': 1, 'Scientists': 1, 'engineers': 1, 'around': 1, 'world': 1, 'collaborate': 1, 'ambitious': 1, 'projects': 1, 'push': 1, 'boundaries': 1, 'thought': 1, 'possible': 1, 'decades': 1, 'ago': 1, 'Looking': 1, 'stars': 1, 'reminds': 1, 'relatively': 1, 'small': 1, 'place': 1, 'yet': 1, 'inspires': 1, 'dream': 1, 'bigger': 1, 'future': 1, 'holds': 1, 'promise': 1, 'discovering': 1, 'new': 1, 'worlds': 1, 'resources': 1, 'perhaps': 1, 'even': 1, 'answering': 1, 'ultimate': 1, 'question': 1, 'whether': 1, 'alone': 1})\n",
            "[('exploration', 2), ('The', 2), ('space', 2), ('us', 2), ('universe', 2), ('Space', 1), ('represents', 1), ('humanity', 1), (\"'s\", 1), ('boldest', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Using the same paragraph from Q1:\n",
        "1. Extract all words with only alphabets using re.findall()\n",
        "2. Remove stop words using NLTK’s stopword list\n",
        "3. Perform stemming with PorterStemmer\n",
        "4. Perform lemmaƟzaƟon with WordNetLemmaƟzer\n",
        "5. Compare the stemmed and lemmaƟzed outputs and explain when you’d prefer one over the other."
      ],
      "metadata": {
        "id": "2SNQRlPuY6F2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordss = re.findall(r'\\b[a-zA-Z]+\\b', s)\n",
        "print(wordss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM9ArNs8qVwf",
        "outputId": "b2441346-a7f1-4753-f5a4-57f863bc5f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Space', 'exploration', 'represents', 'humanity', 's', 'boldest', 'ambition', 'to', 'reach', 'beyond', 'our', 'planet', 'and', 'discover', 'the', 'mysteries', 'of', 'the', 'cosmos', 'The', 'technological', 'innovations', 'developed', 'for', 'space', 'missions', 'have', 'consistently', 'transformed', 'our', 'daily', 'lives', 'from', 'satellite', 'communications', 'to', 'advanced', 'materials', 'Scientists', 'and', 'engineers', 'around', 'the', 'world', 'collaborate', 'on', 'ambitious', 'projects', 'that', 'push', 'the', 'boundaries', 'of', 'what', 'we', 'thought', 'possible', 'decades', 'ago', 'Looking', 'up', 'at', 'the', 'stars', 'reminds', 'us', 'of', 'our', 'relatively', 'small', 'place', 'in', 'the', 'universe', 'yet', 'inspires', 'us', 'to', 'dream', 'bigger', 'The', 'future', 'of', 'space', 'exploration', 'holds', 'promise', 'for', 'discovering', 'new', 'worlds', 'resources', 'and', 'perhaps', 'even', 'answering', 'the', 'ultimate', 'question', 'of', 'whether', 'we', 'are', 'alone', 'in', 'the', 'universe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered = [word for word in wordss if word not in stop_words]\n",
        "print(filtered)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A117VlSfrFKI",
        "outputId": "43f30b46-1f10-4a57-8e5f-8373544c65d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Space', 'exploration', 'represents', 'humanity', 'boldest', 'ambition', 'reach', 'beyond', 'planet', 'discover', 'mysteries', 'cosmos', 'The', 'technological', 'innovations', 'developed', 'space', 'missions', 'consistently', 'transformed', 'daily', 'lives', 'satellite', 'communications', 'advanced', 'materials', 'Scientists', 'engineers', 'around', 'world', 'collaborate', 'ambitious', 'projects', 'push', 'boundaries', 'thought', 'possible', 'decades', 'ago', 'Looking', 'stars', 'reminds', 'us', 'relatively', 'small', 'place', 'universe', 'yet', 'inspires', 'us', 'dream', 'bigger', 'The', 'future', 'space', 'exploration', 'holds', 'promise', 'discovering', 'new', 'worlds', 'resources', 'perhaps', 'even', 'answering', 'ultimate', 'question', 'whether', 'alone', 'universe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "singles = [stemmer.stem(wo) for wo in filtered]\n",
        "print(singles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmBFt4V7rjps",
        "outputId": "e719ff90-f8d6-46db-c117-8593e03038c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['space', 'explor', 'repres', 'human', 'boldest', 'ambit', 'reach', 'beyond', 'planet', 'discov', 'mysteri', 'cosmo', 'the', 'technolog', 'innov', 'develop', 'space', 'mission', 'consist', 'transform', 'daili', 'live', 'satellit', 'commun', 'advanc', 'materi', 'scientist', 'engin', 'around', 'world', 'collabor', 'ambiti', 'project', 'push', 'boundari', 'thought', 'possibl', 'decad', 'ago', 'look', 'star', 'remind', 'us', 'rel', 'small', 'place', 'univers', 'yet', 'inspir', 'us', 'dream', 'bigger', 'the', 'futur', 'space', 'explor', 'hold', 'promis', 'discov', 'new', 'world', 'resourc', 'perhap', 'even', 'answer', 'ultim', 'question', 'whether', 'alon', 'univers']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "lamsingles = [wnl.lemmatize(wo) for wo in filtered]\n",
        "print(lamsingles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E9xJG0YtqMs",
        "outputId": "a745b873-8c53-45a3-e0da-ee51f1969173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Space', 'exploration', 'represents', 'humanity', 'boldest', 'ambition', 'reach', 'beyond', 'planet', 'discover', 'mystery', 'cosmos', 'The', 'technological', 'innovation', 'developed', 'space', 'mission', 'consistently', 'transformed', 'daily', 'life', 'satellite', 'communication', 'advanced', 'material', 'Scientists', 'engineer', 'around', 'world', 'collaborate', 'ambitious', 'project', 'push', 'boundary', 'thought', 'possible', 'decade', 'ago', 'Looking', 'star', 'reminds', 'u', 'relatively', 'small', 'place', 'universe', 'yet', 'inspires', 'u', 'dream', 'bigger', 'The', 'future', 'space', 'exploration', 'hold', 'promise', 'discovering', 'new', 'world', 'resource', 'perhaps', 'even', 'answering', 'ultimate', 'question', 'whether', 'alone', 'universe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Choose 3 short texts of your own (e.g., different news headlines, product reviews).\n",
        "1. Use CountVectorizer to generate the Bag of Words representation.\n",
        "2. Use TfidfVectorizer to compute TF-IDF scores.\n",
        "3. Print and interpret the top 3 keywords from each text using TF-IDF."
      ],
      "metadata": {
        "id": "goVZZrqIt4a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "j-d3TgRdmd4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"Smartphones have revolutionized the way we communicate.\",\n",
        "    \"Electric vehicles are a growing trend in the automotive industry.\",\n",
        "    \"The new iPhone has a better camera and longer battery life.\"\n",
        "]"
      ],
      "metadata": {
        "id": "Abpv0zvLt8Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "X_count = count_vectorizer.fit_transform(texts)"
      ],
      "metadata": {
        "id": "TfAYpYg-mW0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = count_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "44DcmYt5mhyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_count = pd.DataFrame(X_count.toarray(), columns=words)"
      ],
      "metadata": {
        "id": "pWNBYPd5mlPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(texts)"
      ],
      "metadata": {
        "id": "IGUxunIamnwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_words = tfidf_vectorizer.get_feature_names_out()\n",
        "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_words)\n"
      ],
      "metadata": {
        "id": "Sxl2F-kNmqZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, text in enumerate(texts):\n",
        "    print(f\"\\nTop 3 keywords in Text {i+1}: '{text}'\")\n",
        "\n",
        "    sorted_indices = df_tfidf.iloc[i].sort_values(ascending=False).head(3).index\n",
        "    print(f\"Top 3 keywords: {', '.join(sorted_indices)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMYDHl3vmtIo",
        "outputId": "6c5468ff-ba0b-43ae-c091-b4fa699b9884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 3 keywords in Text 1: 'Smartphones have revolutionized the way we communicate.'\n",
            "Top 3 keywords: communicate, smartphones, way\n",
            "\n",
            "Top 3 keywords in Text 2: 'Electric vehicles are a growing trend in the automotive industry.'\n",
            "Top 3 keywords: are, automotive, electric\n",
            "\n",
            "Top 3 keywords in Text 3: 'The new iPhone has a better camera and longer battery life.'\n",
            "Top 3 keywords: and, battery, camera\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Write 2 short texts (4–6 lines each) describing two different technologies (e.g., AI vs\n",
        "Blockchain).\n",
        "1. Preprocess and tokenize both texts.\n",
        "2. Calculate:\n",
        "\n",
        "* a. Jaccard Similarity using sets\n",
        "\n",
        "* b. Cosine Similarity using TfidfVectorizer + cosine_similarity()\n",
        "\n",
        "* c. Analyze which similarity metric gives beƩer insights in your case."
      ],
      "metadata": {
        "id": "fh9Mi279nPhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import string"
      ],
      "metadata": {
        "id": "uHfmdYW9nyHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"Artificial Intelligence refers to the simulation of human intelligence in machines. It involves learning, reasoning, and self-correction. AI is used in various fields like healthcare, finance, and robotics. Its applications range from chatbots to autonomous vehicles.\"\n",
        "text2 = \"Blockchain is a decentralized digital ledger used to store transactions across multiple computers. It is known for its security, transparency, and immutability. Blockchain has applications in cryptocurrencies, supply chains, and digital contracts. It enables secure and verifiable transactions.\""
      ],
      "metadata": {
        "id": "8Q_Dc92Uncio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
        "    return set(text.split())"
      ],
      "metadata": {
        "id": "U0n0y08Jn0pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_text1 = preprocess_text(text1)\n",
        "tokens_text2 = preprocess_text(text2)"
      ],
      "metadata": {
        "id": "eMW80yljn9xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#jaccad\n",
        "intersection = len(tokens_text1.intersection(tokens_text2))\n",
        "union = len(tokens_text1.union(tokens_text2))\n",
        "jaccard_similarity = intersection / union"
      ],
      "metadata": {
        "id": "YxJsaXHloBv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cosine\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform([text1, text2])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]"
      ],
      "metadata": {
        "id": "HkehMPC4oDs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Jaccard Similarity: {jaccard_similarity:.4f}\")\n",
        "print(f\"Cosine Similarity: {cosine_sim:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv7wCNh_oHY0",
        "outputId": "22763153-8fda-4deb-caaa-893b771679cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard Similarity: 0.1455\n",
            "Cosine Similarity: 0.2191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Write a short review for a product or service.\n",
        "1. Use TextBlob or VADER to find polarity & subjectivity for each review.\n",
        "2. Classify reviews into Positive / Negative / Neutral.\n",
        "3. Create a word cloud using the wordcloud library for all positive reviews."
      ],
      "metadata": {
        "id": "Kdpze-HeoRY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "review = \"I recently purchased the seiko smartwatch, and it's been an excellent experience. The design is sleek and modern, and it fits comfortably on my wrist. The battery life is impressive, lasting over 2 days with heavy use. The heart rate monitor and fitness tracking features work great, and I love the ease of syncing it with my phone. Overall, a fantastic purchase, highly recommend!\"\n",
        "blob = TextBlob(review)\n",
        "polarity = blob.sentiment.polarity\n",
        "subjectivity = blob.sentiment.subjectivity\n",
        "\n",
        "if polarity > 0:\n",
        "    review_class = \"Positive\"\n",
        "elif polarity < 0:\n",
        "    review_class = \"Negative\"\n",
        "else:\n",
        "    review_class = \"Neutral\"\n",
        "\n",
        "print(f\"Polarity: {polarity:.4f}\")\n",
        "print(f\"Subjectivity: {subjectivity:.4f}\")\n",
        "print(f\"Review Classification: {review_class}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "todvA_88ocbQ",
        "outputId": "ef8b377e-1ceb-4e65-97a6-99928a1934ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity: 0.3583\n",
            "Subjectivity: 0.5533\n",
            "Review Classification: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Choose your own paragraph (~100 words) as training data.\n",
        "1. Tokenize text using Tokenizer() from keras.preprocessing.text\n",
        "2. Create input sequences and build a simple LSTM or Dense model\n",
        "3. Train the model and generate 2–3 new lines of text starting from any seed word you\n",
        "provide."
      ],
      "metadata": {
        "id": "EEqk6siFox_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4JbclEopd3u",
        "outputId": "af287895-78e6-49a8-9d3d-a5e3283dfa3a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UDyISAhbo8f9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Artificial intelligence is transforming many industries today. From healthcare to finance, AI is revolutionizing processes and automating tasks.\n",
        "It allows businesses to make more informed decisions and improves customer experiences. Machine learning, a subset of AI, enables systems to\n",
        "learn from data and improve over time without explicit programming. As AI continues to evolve, it holds the potential to reshape the future\n",
        "of work and society. However, there are challenges regarding ethics, data privacy, and the impact of automation on employment that must be addressed.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "EkFD3uUProJx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])"
      ],
      "metadata": {
        "id": "EM6wpXHHrvZN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "Qfnai-H-rtua"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in text.split('.'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "lRMMs11Lr0q1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = max([len(x) for x in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')"
      ],
      "metadata": {
        "id": "k2GEcERpr45p"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]"
      ],
      "metadata": {
        "id": "9OPfR6RMr7U4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))\n",
        "model.add(LSTM(150, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_enIkXr6r9zq",
        "outputId": "61220f8b-0377-4ef7-f4c0-d3778e0462f1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=total_words)\n",
        "model.fit(X, y, epochs=100, verbose=1)"
      ],
      "metadata": {
        "id": "qBZ0pY6RsBoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89883a6a-bd17-41f7-b336-c01c235dcd73"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.0000e+00 - loss: 4.2207\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0707 - loss: 4.2056\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0668 - loss: 4.1884\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.0551 - loss: 4.1685\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0551 - loss: 4.1142\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0434 - loss: 4.0646\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0512 - loss: 4.0350\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.0614 - loss: 4.0047\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0677 - loss: 3.9326\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1131 - loss: 3.9176\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1102 - loss: 3.9269\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1477 - loss: 3.8238\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0882 - loss: 3.8302\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1053 - loss: 3.7774\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1258 - loss: 3.6804\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1156 - loss: 3.5808\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1570 - loss: 3.4662\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1116 - loss: 3.5177\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1721 - loss: 3.3446\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1077 - loss: 3.3876\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1243 - loss: 3.3176\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1541 - loss: 3.1852\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1477 - loss: 3.1524\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1399 - loss: 3.0844\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1809 - loss: 3.1080\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1902 - loss: 2.9696\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1721 - loss: 2.9476\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2350 - loss: 2.8311\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2609 - loss: 2.7099\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2321 - loss: 2.7711\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2248 - loss: 2.6804\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1935 - loss: 2.6987\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2477 - loss: 2.5595\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3130 - loss: 2.4641\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3013 - loss: 2.4057\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3599 - loss: 2.3047\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3247 - loss: 2.2980\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3837 - loss: 2.2379\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3515 - loss: 2.2222\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4071 - loss: 2.0432\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4066 - loss: 2.0477\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5158 - loss: 1.9889\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4325 - loss: 1.8769\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4920 - loss: 1.8997\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5314 - loss: 1.8293\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6036 - loss: 1.7550\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5519 - loss: 1.7247\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4719 - loss: 1.7929\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6675 - loss: 1.5775\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5519 - loss: 1.6775\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6554 - loss: 1.5670\n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6178 - loss: 1.4759\n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6831 - loss: 1.4071\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6855 - loss: 1.4630\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7084 - loss: 1.3607\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7328 - loss: 1.3880\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7304 - loss: 1.3884\n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6533 - loss: 1.3561\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7304 - loss: 1.2956\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7499 - loss: 1.1884\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7304 - loss: 1.1918\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8074 - loss: 1.1540\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7947 - loss: 1.1464\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7815 - loss: 1.1347\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8411 - loss: 1.0057\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7572 - loss: 1.0641\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8113 - loss: 1.1158\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7830 - loss: 1.0720\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8113 - loss: 0.9739\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8381 - loss: 0.9542\n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8727 - loss: 0.9326\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8727 - loss: 0.9537\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8123 - loss: 0.9214\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.8655 - loss: 0.8258\n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7337 - loss: 0.9554\n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.8718 - loss: 0.8031\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - accuracy: 0.8869 - loss: 0.7973\n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.8884 - loss: 0.8071\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.9220 - loss: 0.7718\n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8947 - loss: 0.7412\n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9166 - loss: 0.7511\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9332 - loss: 0.6619\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9269 - loss: 0.6777\n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9127 - loss: 0.7063\n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9771 - loss: 0.6190\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9512 - loss: 0.6169\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.9473 - loss: 0.6078\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9049 - loss: 0.6513\n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9795 - loss: 0.5775\n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9473 - loss: 0.5593\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9215 - loss: 0.6195\n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9639 - loss: 0.5290\n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8923 - loss: 0.5678\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9254 - loss: 0.5624\n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9395 - loss: 0.5462\n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9654 - loss: 0.5287\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9449 - loss: 0.5104\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9449 - loss: 0.5249\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9371 - loss: 0.5219\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9820 - loss: 0.4630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ac6f411ae10>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words=2):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted_word_index = np.argmax(predicted_probs)\n",
        "        output_word = tokenizer.index_word[predicted_word_index]\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "seed_word = \"AI\"\n",
        "generated_text = generate_text(seed_word, next_words=3)\n",
        "print(f\"Generated Text: {generated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig_lVuwLsIJ1",
        "outputId": "b7de61c5-7b6e-4fb7-e59f-ec8033aab055"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text: AI continues to evolve\n"
          ]
        }
      ]
    }
  ]
}